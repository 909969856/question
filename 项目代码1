#=======================================================================================#
#                                   库函数导入                                          #
#=======================================================================================#
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_selection import SelectPercentile, f_classif
import numpy as np
import sys
sys.path.append("final_project/")
from feature_format import featureFormat, targetFeatureSplit
from tester import test_classifier,dump_classifier_and_data
import pickle

#=======================================================================================#
#                                 把字典转化成数组                                      #
#=======================================================================================#
features_list = ['poi','salary',\
                'total_stock_value','total_payments','to_messages','long_term_incentive',\
                'exercised_stock_options','deferred_income','deferral_payments','bonus'] 
#features_list = ['poi','salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options',\
                 #'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred',\
                 #'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', \
                 #'director_fees', 'deferred_income', 'long_term_incentive', 'from_poi_to_this_person']


with open("final_project/final_project_dataset.pkl","r") as data_file:
    data_dict = pickle.load(data_file)


my_dataset = data_dict
'''
data_temp =[]
for name in my_dataset:
    temp_list = []
    for feature in features_list:
        if my_dataset[name][feature]=='NaN':
            my_dataset[name][feature]=0
        temp_list.append(float(my_dataset[name][feature]))
    data_temp.append(temp_list)
data = np.array(data_temp)'''
data = featureFormat(my_dataset, features_list, sort_keys = True)
#=========================================================================================#
#                               把特征和标签分开                                          #
#=========================================================================================#
features = []
labels = []

for i in data:
    labels.append(i[0])
    features.append(i[1:])
#=========================================================================================#
#                    用Pipeline把PCA主成分提取和分类器装到一起                            #
#=========================================================================================#
from sklearn.pipeline import Pipeline
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn import svm
from sklearn import tree



pca = PCA(n_components=3)
clf = GaussianNB()
pca_GaussianNB = Pipeline([('pca', pca), ('GaussianNB', clf)])

#clf = svm.SVC(kernel = 'rbf',C = 10)
#pca_svm = Pipeline([('pca', pca), ('svc', clf)])

#clf = tree.DecisionTreeClassifier(min_samples_split=10)
#pca_tree = Pipeline([('pca', pca), ('tree', clf)])
    
#=========================================================================================#
#                            分层随机抽样交叉验证                                         #
#=========================================================================================#
#from sklearn.cross_validation import StratifiedShuffleSplit#旧版本
#sss = StratifiedShuffleSplit(labels, 1000, test_size = 0.1,random_state=0)
#for train,test in sss:

from sklearn.model_selection import StratifiedShuffleSplit
sss = StratifiedShuffleSplit(n_splits=1000, test_size=0.1, random_state=42)

accuracy_score_all = []
precision_score_all = []
recall_score_all= []
f1_score_all = []
f2_score_all =[]

for train,test in sss.split(features,labels):
    true_negatives = 0
    false_negatives = 0
    true_positives = 0
    false_positives = 0
    features_train = [features[i] for i in train]
    labels_train = [labels[i]for i in train]
    features_test = [features[i]for i in test]
    labels_test = [labels[i]for i in test]
    
    pca_GaussianNB.fit(features_train,labels_train)
    predictions = pca_GaussianNB.predict(features_test)
    for prediction, truth in zip(predictions, labels_test):
        if prediction == 0 and truth == 0:
            true_negatives += 1
        elif prediction == 0 and truth == 1:
            false_negatives += 1
        elif prediction == 1 and truth == 0:
            false_positives += 1
        elif prediction == 1 and truth == 1:
            true_positives += 1
        else:
            print "Warning: Found a predicted label not == 0 or 1."
            print "All predictions should take value 0 or 1."
            print "Evaluating performance for processed predictions:"
            break
    
    #pca_svm.fit(features_train,labels_train)
    #print pca_svm.score(features_test,labels_test)
    
    #pca_tree.fit(features_train,labels_train)
    #print pca_tree.score(features_test,labels_test)
    

    print 'true_negatives:',true_negatives
    print 'false_negatives:',false_negatives
    print 'true_positives:',true_positives
    print 'false_positives:',false_positives
    
    

    total_predictions = true_negatives + false_negatives + false_positives + true_positives
    accuracy = 1.0*(true_positives + true_negatives)/total_predictions
    precision = 1.0*true_positives/(true_positives+false_positives)
    recall = 1.0*true_positives/(true_positives+false_negatives)
    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)
    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)

    
    accuracy_score_all.append(accuracy)
    precision_score_all.append(precision)
    recall_score_all.append(recall)
    f1_score_all.append(f1)
    f2_score_all.append(f2)
    
PERF_FORMAT_STRING = "\tAccuracy: {}\tPrecision: {}\tRecall: {}\tF1: {}\tF2: {}"
RESULTS_FORMAT_STRING = "\tTotal predictions: {}\tTrue positives: {}\tFalse positives: {}\tFalse negatives: {}\tTrue negatives: {}"
accuracy_score = np.array(accuracy_score_all).mean()
precision_score = np.array(precision_score_all).mean()
recall_score = np.array(recall_score_all).mean()
f1_score = np.array(f1_score_all).mean()
f2_score = np.array(f2_score_all).mean()
print pca_GaussianNB
print PERF_FORMAT_STRING.format(accuracy_score, precision_score, recall_score, f1_score, f2_score)
print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)
print ""
#print 'accuracy_score:',accuracy_score
#print 'precision_score:',precision_score
#print 'recall_score:',recall_score
#print 'f1_score:',f1_score
#print 'f2_score:',f2_score
#print 'len(accuracy_score_all):',len(accuracy_score_all)
#print 'true_negatives:',true_negatives
#print 'false_negatives:',true_negatives
#print 'true_positives:',true_negatives
#print 'false_positives:',true_negatives

#=========================================================================================#
#                        存储分类器，数据集，和特征列表                                   #
#=========================================================================================#
dump_classifier_and_data(pca_GaussianNB, my_dataset, features_list)
#dump_classifier_and_data(pca_svm, my_dataset, features_list)
#dump_classifier_and_data(pca_tree, my_dataset, features_list)
#=========================================================================================#
#            算法性能：当使用 tester.py 评估性能时，精确度、召回率均至少为 0.3            #
#=========================================================================================#
test_classifier(pca_GaussianNB, my_dataset, features_list, folds = 1000)
#test_classifier(pca_svm, my_dataset, features_list, folds = 1000)
#test_classifier(pca_tree, my_dataset, features_list, folds = 1000)
